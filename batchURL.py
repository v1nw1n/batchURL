import os
import io
import time
import argparse
from bs4 import BeautifulSoup
import threading
import logging
from queue import Queue
from datetime import datetime
from seleniumwire import webdriver  
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.common.exceptions import WebDriverException, TimeoutException
from urllib.parse import urlsplit, urlunsplit
from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage
from PIL import Image as PILImage, ImageOps
from AISupport import *
from selenium.webdriver.firefox.service import Service

# === é…ç½® ===
TARGET_IMG_HIGHT = 200
ROW_HEIGHT = 150
PROJ_INDEX = datetime.now().strftime("%Y%m%d%H%M%S")

# === æ—¥å¿—è®¾ç½® ===
LOG_FILENAME = "batchURL.log"

with open(LOG_FILENAME, 'w', encoding='utf-8') as f:
    f.write('')
logging.basicConfig(
    filename=LOG_FILENAME,
    filemode="a",
    format="%(asctime)s [%(levelname)s] %(message)s",
    level=logging.INFO,
    encoding='utf-8'
)

def print_banner():
    try:
        with open("banner.txt", "r", encoding="utf-8") as f:
            banner = f.read()
            print(banner)
    except FileNotFoundError:
        pass

class ArgumentParserBanner(argparse.ArgumentParser):
    def print_help(self, *args, **kwargs):
        print_banner()
        super().print_help(*args, **kwargs)

type_define = {"1":"æ­£å¸¸ç³»ç»Ÿ",
                "2":"ç™»å½•é¡µ",
                "3":"é”™è¯¯é¡µ",
                "4":"æ¬¢è¿é¡µ",
                "5":"ç™½é¡µ"}

def page_judge(url: str, html: str, http_status: int, imgPath: str, token: str = None) -> str:
    res = None
    if token :
        res =  page_judge_ai(imgPath,token)
    if res is None:
        return page_judge_local(url=url,html=html,http_status=http_status)
    else:
        return res


def page_judge_ai(imgPath,token):

    # imgb64 = base64.b64encode(screenshot).decode("utf-8")
    imgPath = imgTokenSimplizer(imgPath)
    res = agent_call(token=token,imgPath = imgPath,text= PROMPT_PAGE_JUDGE)
    logging.info(f"AI call->{res}:{imgPath}:prompt->PROMPT_PAGE_JUDGE")
    res = getAIResponse(res)
    if res in type_define.keys() :
        return type_define[res]
    else:
        logging.error(f"AI å“åº”å¼‚å¸¸:{res}")
        print(f"AI å¼‚å¸¸,è½¬æœ¬åœ°åˆ¤æ–­,è¯¦æƒ…æŸ¥çœ‹æ—¥å¿—")
    return None


def page_judge_local(url: str, html: str, http_status: int) -> str:
    #TODOï¼šå¾…ä¼˜åŒ– çŠ¶æ€ç -ã€‹title-ã€‹ç»“æ„å¤æ‚åº¦ï¼ˆæ ‡ç­¾æ•°é‡ï¼‰
    if http_status is None:
        http_status = 0
    if  http_status >= 500 or http_status >= 400:
        return type_define["3"]

    #lowered = html.lower()
    soup = BeautifulSoup(html, 'html.parser')
    # ç®€å•ç»“æ„é¡µåˆ¤æ–­: title ä¸ºç©ºæˆ–å«é”™è¯¯å…³é”®è¯ + é¡µé¢æ ‡ç­¾å°‘
    title = soup.title.string.strip().lower() if soup.title and soup.title.string else ""
    body_tags = soup.find_all(True)
    tag_count = len(body_tags)

    error_keywords = ["404", "not found", "403", "forbidden", "502", "bad gateway", "error"]
    keyword_hit = [kw for kw in error_keywords if  kw in title]

    if keyword_hit:
        logging.info(f"URL å‘½ä¸­å…³é”®è¯ {keyword_hit}: {url}")
        if tag_count < 30:
            return type_define["3"]
        return type_define["3"]

    return type_define["1"]

SCREENSHOTS_DIR = ".\\screeshots\\"

def resize_image(image_bytes, target_height=TARGET_IMG_HIGHT,idx = None):
    img = PILImage.open(io.BytesIO(image_bytes))

    if idx is not None and isinstance(idx,int):
        os.makedirs(SCREENSHOTS_DIR, exist_ok=True)
        img.save(os.path.join(SCREENSHOTS_DIR, f"{PROJ_INDEX}_{idx}.png"), format="PNG", optimize=True)
    h_percent = target_height / float(img.size[1])
    w_size = int(img.size[0] * h_percent)
    img = img.resize((w_size, target_height), PILImage.LANCZOS)
    img = ImageOps.expand(img, border=2, fill='black')
    buffer = io.BytesIO()
    img.save(buffer, format="PNG", optimize=True)
    buffer.seek(0)
    return buffer

# === åˆ›å»ºæµè§ˆå™¨å®ä¾‹ ===
def create_browser():
    options = FirefoxOptions()
    options.add_argument("--headless")
    options.accept_insecure_certs = True
    service = Service(os.environ.get('geckodriver_exe'))
    driver = webdriver.Firefox( seleniumwire_options={}, options=options,service=service )
    driver.set_page_load_timeout(15)
    return driver

# === è·å–çŠ¶æ€ç  ===
def normalize_url(url: str):
    parts = urlsplit(url)
    # ä¸¢å¼ƒ fragment
    return urlunsplit((parts.scheme, parts.netloc, parts.path, parts.query, ''))


def get_status_code(driver):
    try:
        norm_current = normalize_url(driver.current_url)
        for request in reversed(driver.requests):
            if request.response :
                norm_request = normalize_url(request.url)
                if  norm_request  == norm_current:
                    logging.info(f"è·å– HTTP å“åº”ç : {request.response.status_code}:{ request.url}")
                    return request.response.status_code
    except Exception as e:
        logging.exception(f"è·å– HTTP å“åº”ç å¤±è´¥: {str(e)}:{ request.url}")
        pass
    return -1

# === æµè§ˆå™¨æ± å·¥ä½œçº¿ç¨‹ ===
def worker(thread_id, task_queue, result_dict, lock, llm_token, progress_callback, status_dict):
    driver = create_browser()
    while True:
        try:
            task = task_queue.get(timeout=3)
        except:
            break

        idx, url = task
        try:
            status_dict["current"] = f"çº¿ç¨‹-{thread_id} æ­£åœ¨å¤„ç†: {idx} - {url}"
            driver.get(url)
            time.sleep(2)
            html = driver.page_source
            http_status = get_status_code(driver)
            screenshot = driver.get_screenshot_as_png()
            image = resize_image(image_bytes = screenshot,idx = idx)
            imgPath = os.path.join( os.path.abspath(SCREENSHOTS_DIR), f"{PROJ_INDEX}_{idx}.png")
            logging.info(f"ai call imgPath:{imgPath}")
            status = page_judge(url=url, html = html, http_status = http_status, imgPath = imgPath, token = llm_token)
        except TimeoutException:
            status = "æ— æ³•è®¿é—®(è®¿é—®è¶…æ—¶)"
            image = None
        except WebDriverException:
            status = "æ— æ³•è®¿é—®(Webå¼‚å¸¸)"
            image = None
        except Exception as e:
            status = "æ— æ³•è®¿é—®(å…¶ä»–å¼‚å¸¸)"
            image = None
            logging.exception(f"å¤„ç† {url} å¼‚å¸¸:{e} ")

        with lock:
            result_dict[idx] = {
                "id": idx,
                "url": url,
                "status": status,
                "image": image
            }
            if progress_callback:
                progress_callback()

        task_queue.task_done()

    driver.quit()

# === å†™å…¥ Excel æ–‡ä»¶ ===
def write_excel(results: list, output_path):
    wb = Workbook()
    ws = wb.active
    ws.title = "è®¿é—®ç»“æœ"
    ws.append(["ID", "URL", "è®¿é—®çŠ¶æ€", "æˆªå›¾"])

    for row_num, res in enumerate(results, start=2):
        ws.cell(row=row_num, column=1, value=res["id"])
        ws.cell(row=row_num, column=2, value=res["url"])
        ws.cell(row=row_num, column=3, value=res["status"])
        if res["image"]:
            img = XLImage(res["image"])
            ws.add_image(img, f"D{row_num}")
            ws.row_dimensions[row_num].height = ROW_HEIGHT
        else:
            ws.cell(row=row_num, column=4, value="ï¼ˆæ— æˆªå›¾ï¼‰")
            ws.row_dimensions[row_num].height = 20

    ws.column_dimensions["A"].width = 6
    ws.column_dimensions["B"].width = 50
    ws.column_dimensions["C"].width = 20
    ws.column_dimensions["D"].width = 45
    wb.save(output_path)
    print(f"\nâœ… Excel æ–‡ä»¶å·²ä¿å­˜: {output_path}")

# === è‡ªåŠ¨è®¡ç®—çº¿ç¨‹æ•° ===
def calculate_worker_count(url_count, max_limit=8):
    if url_count <= 10:
        return min(2, url_count)
    elif url_count <= 100:
        return min(4, url_count)
    elif url_count <= 300:
        return min(6, url_count)
    else:
        return min(max_limit, url_count // 20 + 2)


def main():
   
    parser = ArgumentParserBanner(description="æ‰¹é‡è·å–ç›®æ ‡URLè®¿é—®çŠ¶æ€")
    parser.add_argument('-i', '--input', default='urls', help='å®šä¹‰ç›®æ ‡,ä¸€è¡Œä¸€ä¸ªç›®æ ‡(txt)')
    parser.add_argument('-o', '--output', default='url_results', help='å®šä¹‰è¾“å‡ºæ–‡ä»¶åï¼Œä¸åŠ åç¼€')
    parser.add_argument('--llm-token', help='å¼€å¯AIæ”¯æŒ,é…ç½®token')
    parser.add_argument('--friend-ui', action='store_true', help='æ˜¯å¦å¯ç”¨è¿›åº¦æ¡å±•ç¤º(é»˜è®¤å…³é—­)')
    args = parser.parse_args()

    input_file = args.input
    output_excel = f"{args.output}_{PROJ_INDEX}.xlsx"
    llm_token = args.llm_token
    use_progress_bar = args.friend_ui

    if not os.path.exists(input_file):
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_file}")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip()]

    url_count = len(urls)
    if url_count == 0:
        print("â— è¾“å…¥ URL ä¸ºç©º")
        return
    
    if llm_token is not None:
        if is_token_valid(llm_token):
            output_excel = f"{args.output}_{PROJ_INDEX}_AI.xlsx"
            print("âœ…LLM TOKENå·²é…ç½®")
        else :
            llm_token = None
            print("âŒLLM TOKENä¸å¯ç”¨")
        

    worker_count = calculate_worker_count(url_count)
    print(f"ğŸ“Š æ€»è®¡ URL: {url_count}ï¼Œæµè§ˆå™¨æ± çº¿ç¨‹æ•°: {worker_count}")

    start_time = time.time()

    task_queue = Queue()
    for idx, url in enumerate(urls, start=1):
        task_queue.put((idx, url))

    results_dict = {}
    lock = threading.Lock()
    threads = []
    status_dict = {"current": ""}

    progress_count = [0]
    progress_bar = None
    if use_progress_bar:
        try:
            from tqdm import tqdm
            progress_bar = tqdm(total=url_count, desc="å¤„ç†è¿›åº¦", ncols=80)
        except ImportError:
            print("âš ï¸ æœªå®‰è£… tqdm,è¿›åº¦æ¡è‡ªåŠ¨åˆ‡æ¢ä¸ºè½»é‡æ¨¡å¼")
            use_progress_bar = False

    def progress_callback():
        progress_count[0] += 1
        if use_progress_bar and progress_bar:
            progress_bar.update(1)
        else:
            print(f"\rè¿›åº¦: {progress_count[0]}/{url_count}", end="")

    for i in range(worker_count):
        t = threading.Thread(target=worker, args=(i + 1, task_queue, results_dict, lock, llm_token, progress_callback, status_dict))
        t.start()
        threads.append(t)

    for t in threads:
        t.join()

    if progress_bar:
        progress_bar.close()

    results = [results_dict[i] for i in sorted(results_dict.keys())]
    write_excel(results, output_excel)

    end_time = time.time()
    duration = end_time - start_time
    print(f"\nâ±ï¸ å¤„ç†å®Œæ¯•ï¼Œæ€»è€—æ—¶ï¼š{duration:.2f} ç§’ï¼ˆçº¦ {duration / 60:.2f} åˆ†é’Ÿï¼‰")

if __name__ == "__main__":
    main()
