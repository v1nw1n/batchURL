import os
import io
import time
import argparse
from bs4 import BeautifulSoup
import threading
import logging
from queue import Queue
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from seleniumwire import webdriver  
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.common.exceptions import WebDriverException, TimeoutException

from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage
from PIL import Image as PILImage, ImageOps

# === é…ç½® ===
TARGET_IMG_WIDTH = 300
ROW_HEIGHT = 150

# === æ—¥å¿—è®¾ç½® ===
LOG_FILENAME = "batchURL.log"
# å¯åŠ¨æ—¶æ¸…ç©ºæ—¥å¿—æ–‡ä»¶å†…å®¹
with open(LOG_FILENAME, 'w', encoding='utf-8') as f:
    f.write('')
logging.basicConfig(
    filename=LOG_FILENAME,
    filemode="a",
    format="%(asctime)s [%(levelname)s] %(message)s",
    level=logging.INFO,
    encoding='utf-8'
)

def print_banner():
    try:
        with open("banner.txt", "r", encoding="utf-8") as f:
            banner = f.read()
            print(banner)
    except FileNotFoundError:
        pass

class ArgumentParserBanner(argparse.ArgumentParser):
    def print_help(self, *args, **kwargs):
        print_banner()
        super().print_help(*args, **kwargs)

# ===TODO: Token æ£€æŸ¥ï¼ˆé¢„ç•™å®ç°ï¼‰ ===
def is_token_valid(token: str) -> bool:
    return False

# ===TODO: AI åˆ¤æ–­é€»è¾‘ï¼ˆé¢„ç•™å®ç°ï¼‰ ===
def ai_judge_status(url: str, html: str, http_status: int, token: str) -> str:
    return ""

# === æœ¬åœ°/AI åˆ¤æ–­é¡µé¢çŠ¶æ€ ===
def judge_page_status(url: str, html: str, http_status: int, token: str = None) -> str:
    if token and is_token_valid(token):
        return ai_judge_status(url, html, http_status, token)

    #çŠ¶æ€ç -ã€‹title-ã€‹ç»“æ„å¤æ‚åº¦ï¼ˆæ ‡ç­¾æ•°é‡ï¼‰
    if http_status is None or http_status >= 500:
        return "æ— æ³•è®¿é—®(5xx)"
    elif http_status >= 400:
        return "é¡µé¢å¼‚å¸¸(4xx)"

    lowered = html.lower()
    soup = BeautifulSoup(html, 'html.parser')
    

    # ç®€å•ç»“æ„é¡µåˆ¤æ–­: title ä¸ºç©ºæˆ–å«é”™è¯¯å…³é”®è¯ + é¡µé¢æ ‡ç­¾å°‘
    title = soup.title.string.strip().lower() if soup.title and soup.title.string else ""
    body_tags = soup.find_all(True)
    tag_count = len(body_tags)

    error_keywords = ["404", "not found", "403", "forbidden", "502", "bad gateway", "error"]
    keyword_hit = [kw for kw in error_keywords if  kw in title]

    if keyword_hit:
        logging.info(f"URL å‘½ä¸­å…³é”®è¯ {keyword_hit}: {url}")
        if tag_count < 30:
            return "é¡µé¢å¼‚å¸¸(ç»“æ„ç®€å•)"
        return "é¡µé¢å¼‚å¸¸(ç›®æ ‡å­˜æ´»)"

    return "æ­£å¸¸"

# === ç¼©æ”¾å›¾åƒå¹¶åŠ è¾¹æ¡† ===
def resize_image(image_bytes, target_width=TARGET_IMG_WIDTH):
    img = PILImage.open(io.BytesIO(image_bytes))
    w_percent = target_width / float(img.size[0])
    h_size = int((float(img.size[1]) * float(w_percent)))
    img = img.resize((target_width, h_size))
    img = ImageOps.expand(img, border=2, fill='black')
    buffer = io.BytesIO()
    img.save(buffer, format="PNG")
    buffer.seek(0)
    return buffer

# === åˆ›å»ºæµè§ˆå™¨å®ä¾‹ ===
def create_browser():
    options = FirefoxOptions()
    options.add_argument('--headless')
    options.accept_insecure_certs = True
    driver = webdriver.Firefox(seleniumwire_options={}, options=options)
    driver.set_page_load_timeout(15)
    return driver

# === è·å–çŠ¶æ€ç  ===
def get_status_code(driver):
    try:
        for request in reversed(driver.requests):
            if request.response and request.url == driver.current_url:
                return request.response.status_code
    except Exception:
        pass
    return None

# === æµè§ˆå™¨æ± å·¥ä½œçº¿ç¨‹ ===
def worker(thread_id, task_queue, result_dict, lock, llm_token, progress_callback, status_dict):
    driver = create_browser()
    while True:
        try:
            task = task_queue.get(timeout=3)
        except:
            break

        idx, url = task
        try:
            status_dict["current"] = f"çº¿ç¨‹-{thread_id} æ­£åœ¨å¤„ç†: {idx} - {url}"
            driver.get(url)
            time.sleep(2)
            html = driver.page_source
            http_status = get_status_code(driver)
            screenshot = driver.get_screenshot_as_png()
            image = resize_image(screenshot)
            status = judge_page_status(url, html, http_status, token=llm_token)
        except TimeoutException:
            status = "æ— æ³•è®¿é—®ï¼ˆè®¿é—®è¶…æ—¶ï¼‰"
            image = None
        except WebDriverException:
            status = "æ— æ³•è®¿é—®ï¼ˆWebå¼‚å¸¸ï¼‰"
            image = None
        except Exception:
            status = "æ— æ³•è®¿é—®ï¼ˆå…¶ä»–å¼‚å¸¸ï¼‰"
            image = None
            logging.exception(f"å¤„ç† URL å¼‚å¸¸: {url}")

        with lock:
            result_dict[idx] = {
                "id": idx,
                "url": url,
                "status": status,
                "image": image
            }
            if progress_callback:
                progress_callback()

        task_queue.task_done()

    driver.quit()

# === å†™å…¥ Excel æ–‡ä»¶ ===
def write_excel(results: list, output_path):
    wb = Workbook()
    ws = wb.active
    ws.title = "è®¿é—®ç»“æœ"
    ws.append(["ID", "URL", "è®¿é—®çŠ¶æ€", "æˆªå›¾"])

    for row_num, res in enumerate(results, start=2):
        ws.cell(row=row_num, column=1, value=res["id"])
        ws.cell(row=row_num, column=2, value=res["url"])
        ws.cell(row=row_num, column=3, value=res["status"])
        if res["image"]:
            img = XLImage(res["image"])
            ws.add_image(img, f"D{row_num}")
            ws.row_dimensions[row_num].height = ROW_HEIGHT
        else:
            ws.cell(row=row_num, column=4, value="ï¼ˆæ— æˆªå›¾ï¼‰")
            ws.row_dimensions[row_num].height = 20

    ws.column_dimensions["A"].width = 6
    ws.column_dimensions["B"].width = 50
    ws.column_dimensions["C"].width = 20
    ws.column_dimensions["D"].width = 45
    wb.save(output_path)
    print(f"\nâœ… Excel æ–‡ä»¶å·²ä¿å­˜: {output_path}")

# === è‡ªåŠ¨è®¡ç®—çº¿ç¨‹æ•° ===
def calculate_worker_count(url_count, max_limit=8):
    if url_count <= 10:
        return min(2, url_count)
    elif url_count <= 100:
        return min(4, url_count)
    elif url_count <= 300:
        return min(6, url_count)
    else:
        return min(max_limit, url_count // 20 + 2)

# === ä¸»å‡½æ•° ===
def main():
   
    parser = ArgumentParserBanner(description="æ‰¹é‡è·å–ç›®æ ‡URLè®¿é—®çŠ¶æ€")
    parser.add_argument('-i', '--input', default='urls', help='å®šä¹‰ç›®æ ‡ï¼Œä¸€è¡Œä¸€ä¸ªç›®æ ‡ï¼ˆtxtï¼‰')
    parser.add_argument('-o', '--output', default='url_results', help='å®šä¹‰è¾“å‡ºæ–‡ä»¶åï¼Œä¸åŠ åç¼€')
    parser.add_argument('--llm-token', help='å¼€å¯AIæ”¯æŒï¼Œé…ç½®token')
    parser.add_argument('--friend-ui', action='store_true', help='æ˜¯å¦å¯ç”¨è¿›åº¦æ¡å±•ç¤ºï¼ˆé»˜è®¤å…³é—­ï¼‰')
    args = parser.parse_args()

    input_file = args.input
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_excel = f"{args.output}_{timestamp}.xlsx"
    llm_token = args.llm_token
    use_progress_bar = args.friend_ui

    if not os.path.exists(input_file):
        print(f"âŒ æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ï¼š{input_file}")
        return

    with open(input_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip()]

    url_count = len(urls)
    if url_count == 0:
        print("â— è¾“å…¥ URL ä¸ºç©º")
        return

    worker_count = calculate_worker_count(url_count)
    print(f"ğŸ“Š æ€»è®¡ URL: {url_count}ï¼Œæµè§ˆå™¨æ± çº¿ç¨‹æ•°: {worker_count}")

    start_time = time.time()

    task_queue = Queue()
    for idx, url in enumerate(urls, start=1):
        task_queue.put((idx, url))

    results_dict = {}
    lock = threading.Lock()
    threads = []
    status_dict = {"current": ""}

    progress_count = [0]
    progress_bar = None
    if use_progress_bar:
        try:
            from tqdm import tqdm
            progress_bar = tqdm(total=url_count, desc="å¤„ç†è¿›åº¦", ncols=80)
        except ImportError:
            print("âš ï¸ æœªå®‰è£… tqdmï¼Œè¿›åº¦æ¡è‡ªåŠ¨åˆ‡æ¢ä¸ºè½»é‡æ¨¡å¼")
            use_progress_bar = False

    def progress_callback():
        progress_count[0] += 1
        if use_progress_bar and progress_bar:
            progress_bar.update(1)
        else:
            print(f"\rè¿›åº¦: {progress_count[0]}/{url_count}", end="")

    for i in range(worker_count):
        t = threading.Thread(target=worker, args=(i + 1, task_queue, results_dict, lock, llm_token, progress_callback, status_dict))
        t.start()
        threads.append(t)

    for t in threads:
        t.join()

    if progress_bar:
        progress_bar.close()

    results = [results_dict[i] for i in sorted(results_dict.keys())]
    write_excel(results, output_excel)

    end_time = time.time()
    duration = end_time - start_time
    print(f"\nâ±ï¸ å¤„ç†å®Œæ¯•ï¼Œæ€»è€—æ—¶ï¼š{duration:.2f} ç§’ï¼ˆçº¦ {duration / 60:.2f} åˆ†é’Ÿï¼‰")

if __name__ == "__main__":
    main()
